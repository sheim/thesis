% !TEX root = ../root.tex

\chapter{Introduction} \label{chap:intro}
\epigraph{To tell the truth, we don't do it because it is useful, but because it is amusing.}{Archibald Vivian Hill}

This cumulative thesis presents the four first-author papers I published during my Ph.D. studies in the Dynamic Locomotion Group of the Max Planck Institute for Intelligent Systems, Stuttgart. The main contribution of these studies is an extension of viability theory into state-action space and a measure over viable sets in this space. This provides the formal mathematical objects to rigorously analyze several aspects of dynamics, including the robustness of a given system design prior to controller design. \par
Each paper is attached in the appendix. The thesis itself serves to facilitate reading the papers and understanding their import in the broader context. The thesis is organized as follows: in chapter \ref{chap:intro} (this chapter), I introduce the overall motivation and objectives.
Chapter \ref{chap:prelims} concisely covers the background knowledge and related work.
Chapter \ref{chap:pubs} summarizes each publication, my contributions, and suggests an order in which to read them.
Finally, in chapter \ref{chap:discussion}, I discuss the contributions of publications in relation to the overall theme and motivation and the open challenges they raise.

\section{Overall Motivation}

Dynamics are most certainly one of the most fascinating domains to study, and motion is dynamics embodied. To observe motion, whether that of a squirrel gracefully leaping from one branch to another, or the oscillating ebb and flow of water swirling around an unusual rock formation in a river, is a pleasure in and of itself. And to understand this motion, even more so. \par

If this were not motivation enough, motion and mobility are entrenched in every aspect of modern society. It is our ability to move people, goods, and information quickly, cheaply, and reliably that enables a global economy and society. The advent of mobile robots that can automate mobility promises to once again change scales of what we consider far or "just around the corner". Automation will allow mobility at a lower cost and in situations where it is unsafe or otherwise undesirable to employ humans. Even without an increase in speed, automation can reduce the time involving the user to virtually nil. The subjective speed, defined as the distance covered over time spent by the user, would increase to unprecedented levels. Nonetheless, for this to become an every-day reality requires a level of robustness and reliability that we can so far only obtain in controlled laboratory settings, where models can be refined to high accuracy CITATION. \par

Robustness to uncertainties is critical for deploying robots in the real world for many reasons.
Sensing is always imperfect, and therefore a robot needs to be robust to these uncertainties.
Controllers are typically designed based on a model of the robot and the world. Since all models are wrong, some amount of robustness is always necessary, even in the most benign settings.
Even with a very well chosen model and excellent system identification, the accuracy of the model used will decay over time.
The robot's dynamics will change due to wear and tear, and the world the robot moves in will change.
In realistic field deployments, it will become common for the robot to be used and even modified in unforeseen ways.
Robustness will also help lower manufacturing costs since performance will be more tolerant of low-precision manufacturing.
Finally, as will be discussed in more detail in this thesis, robustness plays a crucial role in enabling \emph{learning} control.
\par
Machine learning, especially reinforcement learning, is gaining a lot of traction in the community of robotics. Learning control directly from data circumvents the inaccuracies of models, and also allows the robot to adapt to changes in the real world continuously.
A general learning algorithm would also reduce the engineering effort required to deploy a new robot, as the controller design would be automated.
However, we still lack learning algorithms that generalize, are data-efficient, and adequately consider essential aspects such as safety.
A less studied aspect of the same problem is how these systems should be designed. Although it there is some published evidence~\cite{tedrake2005learning, randlov2000shaping} that appropriate system dynamics can significantly facilitate learning, as well as ample informal consensus\footnote{At almost conference I've attended with a mixed audience, a biologist will point out to the engineers that animals often fall, and this is important for learning. The engineers then invariably agree that robots should be designed to allow for this, and that's the end of the story.}, there have been few formal studies that rigorously show which aspects are important. This formalization is the main topic of this thesis.

\section{Objectives}
\emph{How can we enable robots to learn control model-free and directly on hardware?} \par
I believe robots of the future will be able to effectively leverage models, and therefore make extensive use of both simulation and optimal control.
Nonetheless, I have chosen a guiding question that explicitly excludes these two tools for a very deliberate reason: it moves the focus to aspects that I believe have not received sufficient attention. \par
First and foremost is the necessity for robustness. The complete lack of a model heavily emphasizes this need. Indeed, the absence of a model can be loosely thought of as having a model over which we have absolutely no certainty.
Learning directly on hardware also emphasizes the need for robustness, as failures become a significant problem. Failures can cause damage to the robot or world, often require time-consuming resets, and perhaps most importantly, they typically do not provide rich gradient information. \par
Second, as anyone who has worked on real robots will tell you, the hardware design and implementation immediately take a central role. Robots that are appropriately designed and well manufactured are a lot easier to work with and greatly alleviate a control designer's work\footnote{I recently spoke with a researcher at Google Brain, where they have 5 Minitaur quadruped robots, some of which were produced in different batches. Due to the differences in production, they behave slightly differently, and the researcher confirmed they have their favorites for testing learning algorithms.}. When learning control, it is reasonable to expect a learning agent to reap the same benefits, even though we cannot fully describe what these benefits are. \par

More specifically, we will aim to formalize an understanding of how morphology, or hardware design, influences how easy it is to design or learn a control policy. Furthermore, we will aim for a more principled understanding of how a learning agent can learn despite failures, and perhaps more importantly, directly reason about failure.

% How can we enable model-free learning directly in hardware?
% We pose this question, not because we think it is the most useful approach to use in practice: whenever a decent model of the dynamics is available it should be leveraged, both to design controllers and for simulations. However, this question forces our answers to explicitly address our motivation of pushing robustness, taking into consideration the system design, and not relying on massive amounts of data instead of formal understanding.

% - formality of dynamics comes from control theory. However, this is usually limited to design of the controller.
% - There is also extensive work in bifurcation diagrams etc. These typically either assume a passive system (e.g. no control), or manage the controller by assuming an optimal controller. This clearly cannot hold for a learning agent.
% - most tools are centered around convergence.