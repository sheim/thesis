% !TEX root = ../root.tex

\chapter{Introduction} \label{chap:intro}
\epigraph{To tell the truth, we don't do it because it is useful, but because it is amusing.}{Archibald Vivian Hill}

This cumulative thesis presents the four first-author papers I published during my phd studies in the Dynamic Locomotion Group of the Max Planck Institute for Intelligent Systems, Stuttgart. The main contribution of these studies is an extension of viability theory into state-action space, and a measure over viable sets in this space. This provides the formal mathematical objects to rigorously analyze several aspects of dynamics, such as the robustness of a given system design prior to controller design. \par
Each paper is attached in the appendix. The thesis itself serves to facilitate reading the papers and understanding their import in the larger context. The thesis is organized as follows: chapter \ref{chap:intro} (this chapter), I introduce the overall theme and motivation.
Chapter \ref{chap:prelims} concisely covers the background knowledge needed.
Chapter \ref{chap:pubs} summarizes each publication and its contribution, and suggests an order in which to read them.
Finally, in chapter \ref{chap:discussion} I discuss the contributions of publications in relation to the overall theme and motivation, and the open challenges they raise.

\section{Overall Motivation}

Dynamics are most certainly one of the most fascinating domains to study, and motion is dynamics embodied. To observe motion, whether that of a squirrel gracefully leaping from one branch to another, or the oscillating ebb and flow of water swirling around an unusual rock formation in a river, is a pleasure in and of itself. And to understand this motion, even more so. \par

If this were not motivation enough, motion and mobility are entrenched in every aspect of of modern society. It is our ability to move people, goods and information quickly, cheaply and reliably that enables a global economy and society. The advent of mobile robots that can automate mobility promises to once again change scales of what is considered far or "just around the corner". Automation will allow mobility at lower cost and in situations where it is unsafe or otherwise undesirable to employ humans. Even without an increase in speed, automation can reduce the time involving the user to virtually nil. The subjective speed, defined as distance covered over time spent by the user, would increase to unprecedented levels. Nonetheless, for this to become an every-day reality requires a level of robustness and reliability that is so far only achieved in controlled laboratory settings, where models can be refined to high accuracy CITATION. \par

Robustness to uncertainties is critical for deploying in the field, for many reasons.
Sensing is always imperfect, and therefore a robot needs to be robust to these uncertainties.
Controllers are typically designed based on a model of the robot and the world. Since all models are wrong, some amount of robustness is always necessary, even in the most benign settings.
Even with a very well chosen model and excellent system identification, the accuracy of the model used will decay over time.
The robot's dynamics will change due to wear and tear, the world the robot moves in will change.
In realistic field deployments, it will become common for the robot to be used and even modified in unforeseen ways.
Improving robustness will also help lower manufacturing costs, since performance will be more tolerant to low-precision manufacturing.
Finally, as will be discussed in more detail in this thesis, robustness plays a key role in enabling \emph{learning} control.


\par

Machine learning, in particular reinforcement learning, is gaining a lot of traction in the community of robotics. Learning control directly from data promises to effectively address many of the challenges stated above.
Learning from data circumvents the inaccuracies of 

Machine learning is expected to help solve this aspect by providing data-driven controller synthesis. Previous efforts in classical robust control methods can provide some level of robustness to model inaccuracies. However, it is difficult for a designer to imagine, and therefore model, every possible situation a robot may encounter in the field. Employing a continuous, data-driven learning algorithm ensures that the robot can continuously adapt to real-world situations as it encounters them. How these algorithms should be designed is an open challenge currently receiving wide attention CITATIONS. \par

A less studied aspect of the same problem, is how these systems should be designed. Although it there is some published evidence~\cite{tedrake2005learning, randlov2000shaping} that appropriate system dynamics can greatly facilitate learning, as well as ample informal consensus\footnote{At almost conference I've attended with a mixed audience, a biologist will point out to the engineers that animals often fall, and this is important for learning. The engineers then invariably agree that robots should be designed to allow for this, and that's the end of the story.}, there have been few formal studies that rigorously show which aspects are important. This formalization is the main topic of this thesis.

\section{Objectives}
\emph{How can we enable robots to learn control model-free and directly on hardware?} \par
I believe robots of the future will be able to effectively leverage models, and therefore also make extensive use of both simulation and optimal control.
Nonetheless, I have chosen a guiding question which excludes these two tools, for a very deliberate reason: it moves the focus to aspects which I believe have not received sufficient attention. \par
First and foremost is the necessity for robustness. The complete lack of a model heavily emphasizes this need. Indeed, the absence of a model can be loosely thought of as having a model over which we have absolutely no certainty.
Learning directly on hardware also emphasizes the need for robustness, as failures become a major problem. Failures can cause damage to the robot or world, often require time-consuming resets, and perhaps most importantly they typically do not provide rich gradient information. \par
Second, as anyone who has worked on real robots will tell you, the hardware design and implementation immediately takes a central role. Robots that are appropriately designed and well manufactured are a lot easier to work with, and greatly alleviate a control designers work\footnote{I recently spoke with a researcher at Google Brain, where they had about 5 Minitaur quadruped robots, some of which were produced in different batches. Due to the differences in production, they behaved differently, and the researcher confirmed they had their favorites for testing learning algorithms.}. When learning control, it is reasonable to expect a learning agent to reap the same benefits, even though we cannot fully describe what these benefits are. \par

More specifically, we will aim to formalize an understanding of how morphology, or hardware design, influences how easy it is to design or learn a control policy. Furthermore, we will aim for more principled understanding of how a learning agent can learn despite failures, and perhaps more importantly, directly reason about failure.

% How can we enable model-free learning directly in hardware?
% We pose this question, not because we think it is the most useful approach to use in practice: whenever a decent model of the dynamics is available it should be leveraged, both to design controllers and for simulations. However, this question forces our answers to explicitly address our motivation of pushing robustness, taking into consideration the system design, and not relying on massive amounts of data instead of formal understanding.

- formality of dynamics comes from control theory. However, this is usually limited to design of the controller.
- There is also extensive work in bifurcation diagrams etc. These typically either assume a passive system (e.g. no control), or manage the controller by assuming an optimal controller. This clearly cannot hold for a learning agent.
- most tools are centered around convergence.